# LLM Usage Report: Confuc-IO Compiler

## Models Used

- **Claude Opus** — Primary code generation. 100% of the codebase was generated by this model.
- **Gemini 3 Pro** — High-level architecture, design decisions, and project planning.

## The Case Study

Confuc-IO was conceived as a case study: can an AI build an entire compiler for a language designed to confuse it? The developer did not write any code directly. Instead, every line was produced by the LLM through iterative prompting — writing code, finding AI mistakes, and prompting fixes until the output was correct.

## The Core Problem: AI vs. Intentional Confusion

The LLM got predictably confused. Its entire training tells it that `+` means addition, `if` means conditional, and `int` means integer. Confuc-IO says otherwise: `/` is addition, `func` is if, and `Float` is integer. The model's strong bias toward "correct" code became a liability — it would silently autocorrect the confusing mappings back to conventional ones, produce "right-looking" code that was actually wrong for Confuc-IO, and miss bugs in mapping logic because the buggy code looked conventional.

### The Fix: A Reference File

The most effective mitigation was maintaining `confucio_mappings.py` as a canonical reference. With a single source of truth for all keyword, type, operator, and delimiter mappings, the AI could always check before making a decision. This dramatically reduced hallucination on mapping-related code. Referencing this file explicitly at the start of each session became standard practice.

## Scope Trade-offs

As expected, the project couldn't be too complex. Many standard language features (closures, classes, generics, module system, nested scopes) were deliberately left out to keep the focus on getting the confusing mappings right across all compiler phases. Adding more features would have multiplied the surface area for mapping errors, which was already the primary source of bugs.

## Results

Overall, the AI performed better than expected given the magnitude of the project. A full compiler pipeline — parser, AST builder, semantic analyzer, LLVM code generator, JIT execution, AOT compilation — was produced entirely through prompting. The final compiler passes all 16 automated tests, compiles and runs programs correctly via both JIT and AOT, and the codebase is well-structured with a clean separation of concerns.

The estimated overhead from mapping confusion was 20–30%: additional verification cycles, re-explaining context between sessions, and undoing autocorrections. This is acceptable given that the AI handled all conventional compiler engineering (LLVM integration, C stdlib linking, control flow generation, string operations) without issue.

---

*P.S. — In the spirit of full transparency and consistency, this report was also AI-generated. If any of the above sounds confused, well... that's on brand.*
